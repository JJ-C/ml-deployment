# Production Spark cluster configuration example
# Copy this to feature_store.yaml when deploying to production

project: ml_platform_poc
registry: s3://your-bucket/feast/registry.db  # Use S3/GCS for production
provider: local
online_store:
  type: cassandra
  hosts:
    - cassandra-node-1
    - cassandra-node-2
    - cassandra-node-3
  port: 9042
  keyspace: feast_online_store
  protocol_version: 4
  username: ${CASSANDRA_USER}
  password: ${CASSANDRA_PASSWORD}
offline_store:
  type: file
entity_key_serialization_version: 3
batch_engine:
  type: spark
  spark_conf:
    # Cluster configuration
    spark.master: "spark://spark-master:7077"
    
    # Resource allocation
    spark.executor.instances: "10"
    spark.executor.cores: "4"
    spark.executor.memory: "8g"
    spark.driver.memory: "4g"
    spark.driver.cores: "2"
    
    # Performance tuning
    spark.sql.shuffle.partitions: "200"
    spark.default.parallelism: "200"
    spark.sql.execution.arrow.pyspark.enabled: "true"
    spark.sql.adaptive.enabled: "true"
    spark.sql.adaptive.coalescePartitions.enabled: "true"
    
    # Parquet optimization
    spark.sql.parquet.compression.codec: "snappy"
    spark.sql.parquet.mergeSchema: "false"
    spark.sql.parquet.filterPushdown: "true"
    
    # Cassandra connector (if using direct Spark-to-Cassandra writes)
    # spark.cassandra.connection.host: "cassandra-node-1,cassandra-node-2"
    # spark.cassandra.auth.username: "${CASSANDRA_USER}"
    # spark.cassandra.auth.password: "${CASSANDRA_PASSWORD}"
    
    # Network and timeout settings
    spark.network.timeout: "800s"
    spark.executor.heartbeatInterval: "60s"
    
    # Dynamic allocation (optional)
    spark.dynamicAllocation.enabled: "true"
    spark.dynamicAllocation.minExecutors: "2"
    spark.dynamicAllocation.maxExecutors: "20"
    spark.dynamicAllocation.initialExecutors: "5"
